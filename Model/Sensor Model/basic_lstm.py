# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fGJ2_cVPsWGpI-3C_6fOhdqB-_hJURtQ
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

data1 = pd.read_csv('/content/sensor_data_nRF_IMU_1_19092025_164551_not_labelled.csv')
data2 = pd.read_csv('/content/sensor_data_nRF_IMU_2_19092025_164551_labelled.csv')

data1.head()

data2.head()

data2 = data2.drop('Unnamed: 11', axis=1)
data2.head()

data2.dropna(inplace=True)
data2.head()

data = pd.merge(data1, data2, on=['TimeStamp'])
data.head()

data.info()

X = data.drop(['Position','TimeStamp'], axis=1).values
y = data['Position'].values

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

y

y=y-1

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

sequence_length = 50

def create_sequences(X, y, seq_len):
    Xs, ys = [], []
    for i in range(len(X) - seq_len):
        Xs.append(X[i:(i + seq_len)])
        ys.append(y[i + seq_len])
    return np.array(Xs), np.array(ys)

X_seq, y_seq = create_sequences(X, y, sequence_length)

X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)

model = Sequential([
    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
    Dropout(0.3),
    LSTM(64),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(len(np.unique(y)), activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc:.2f}")

print("Thank You")